- [Overview](#overview)
    - [Built With](#built-with)
    - [Structure](#structure)
- [Installation](#installation)
    - [Prerequisites](#prerequisites)
    - [Setup](#setup)
- [Result](#result)


## Overview

### Built with

Project uses technologies
Ruby 3.2, Rails 7.0, PostgreSQL 16.2, Redis 7.2, sidekiq, Docker, Docker Compose, Makefile

### Structure

Project consists from 4 services:

1. `app`

Ruby / Ruby on Rails simplified backend service for a blog application.

2. `db`

PostgreSQL database used as storage of data for app service.

3. `worker`

Service for background job processing. It used gem `sidekiq`.

4. `redis`

Data store used by `worker` service.

5. `web`

Nginx 

## Installation

### Prerequisites

The following  must be installed:
- **docker**              (must docker 25 or newer)
- **docker compose**      (must be docker compose v2  [Check more in detail](https://docs.docker.com/compose/migrate/))
- **git**
- **make**

### Setup

This instruction shows how to run csv file import locally in production environment.
(Copyying master.key from example.master.key is just for convenience to run csv file import locally
in production environment. For real production environment must change master.key and credentials.yml.enc, 
regenerate files)

1.  To download the project, use `git clone`

***
All the following commands use inside the root project directory
***

2.  Create necessary configuration for project setup:

```bash
cp docker/.env.production.example docker/.env.production
cp config/example.master.key config/master.key
cp config/example.credentials.yml.enc config/credentials.yml.enc

```

4. Start docker services in production environment, using the command:
 ```bash
make up-prod
```

6. Prepare database:
```bash
make prepare-db-prod
``` 
6. Generate csv file:
```bash
make generate-csv-prod
``` 
7. Import comments from csv file into blog application in production environment:
```bash
make import-comments-prod
```

## Result

The task used for optimization:

- `gem "activerecord-import"` 
- `gem "smarter_csv"`
- `gem "sidekiq"`
- processing in batches

The following is the output of importing comments from csv file:

```bash
make import-comments-prod
```

```bash
I, [2024-06-03T20:24:18.019247 #69]  INFO -- : [ActiveJob] [Csv::ImportCommentsJob] [97b589ee-137f-4ffc-bd60-dace48a65421] Performing Csv::ImportCommentsJob (Job ID: 97b589ee-137f-4ffc-bd60-dace48a65421) from Sidekiq(demo_blog_app_production_high) enqueued at  with arguments: "comments.csv"
I, [2024-06-03T20:24:22.361613 #69]  INFO -- : [ActiveJob] [Csv::ImportCommentsJob] [97b589ee-137f-4ffc-bd60-dace48a65421] Performed Csv::ImportCommentsJob (Job ID: 97b589ee-137f-4ffc-bd60-dace48a65421) from Sidekiq(demo_blog_app_production_high) in 4342.45ms
```

Running the command to import comments from csv file took 4342.45ms = 4.3 seconds.

Validation errors for comments can find in the log file:
```bash
docker compose exec app bash -c "vim log/production_csv.log"
```

# Test Application

## Objective
The objective of this test case is to evaluate your ability to import data from a CSV file generated by the generate_comments_csv.rb script.
You have to assume that the provided blog application is a production environment running application and must consider all scenarios relevant for this situation.


## Prerequisites
A running instance of the Rails blog application.
The generate_comments_csv.rb script has been executed and a comments.csv file has been generated.
The comments.csv file is located in the root directory of the Rails application.

### Steps
Create a Rubt script to handle the import of comments from the CSV file into the Rails application. The task should:

- Read the comments.csv file.
- For each row in the CSV, find the corresponding Post by its slug.
- Create a new Comment associated with the found Post
- Handle and report any validation errors.

## Considerations

A perfectly written script is not important, however, considerations must be made for this being an active production environment.  This includes things like
validation failures and what the users may experience while the import is running.


The point is to be prepared during the technical interview to answer as many edge case questions about the script, strengths and weaknesses of your approach
